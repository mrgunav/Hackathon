{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numbers\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression , Lasso , Ridge, ElasticNet, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR , LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train = pd.read_csv('Data_Train.csv');\n",
    "org_test = pd.read_csv('Data_Test.csv');\n",
    "print('org_train',org_train.shape);\n",
    "print('org_test',org_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_test['Views'] = np.nan;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data = pd.concat([org_train,org_test],axis='rows',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(org_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_data[pd.isnull(org_data['Song_Name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_data.drop(org_data.index[31398],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Genre'].replace({'all-music' : 'allmusic'},inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genList = pd.unique(org_data['Genre']).tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Name'].replace({\n",
    "  '3' : 'custhree',\n",
    "  'â˜ ï¸SÊœá´€Ê€á´€X OÒ“Ò“Éªá´„Éªá´€ÊŸâ˜ ï¸' : 'cuselectronic',\n",
    "  \"[DJWiLlY '19]✔\" : 'cusdjwilly',\n",
    "  '☆LiL PEEP☆' : 'cuslilpeepa',\n",
    "  '★☞ Azteca PDLK ☜★' : 'cusazteca',\n",
    "  'Ã‘engo Flow Official' : 'cusanengo',\n",
    "  'Đ.BoomBaa 🐱🐱🐱' : 'cusboombaa',\n",
    "  '↪ DJ JUNINHO 22' : 'cusjuniho',\n",
    "  'ä»™æ°´é¢¨æ¥½' : 'cusaeec',\n",
    "  '༄ Tha Trickaz ☁' : 'custrick',\n",
    "  'Đạt BoomBaa' : 'cusatboom',\n",
    "  'Äá»©c Durex' : 'cusdurex',\n",
    "  'Adictos A Los Corridosâœ…' : 'cusadictos',\n",
    "  'áƒ¦ ìŠˆë¹„_[à¹‘B T Sà¹‘]' : 'cusafis',\n",
    "  'AminÃ©' : 'cusamino',\n",
    "  'Anuel AA ✅' : 'cusAnuel',\n",
    "  \"Ar'mon And Trey\" : 'custrey',\n",
    "  '♤♡♢♧El Fran Rt♤♡♢♧' : 'cusfrance',\n",
    "  \"A'SOUNG\" : 'cussoung',\n",
    "  'Atif Aslam ✪' : 'cusaslam',\n",
    "  'Bad Bunny â€“ X100Pre (Ãlbum)' : 'cusbadbunny',\n",
    "  'boppin™' : 'cusboppina',\n",
    "  'Bean Xinh ❂' : 'cusbeanxin',\n",
    "  'Bảo Huỳnh' : 'cusbaeohua',\n",
    "  'Chuoi Tây ✪' : 'cuschuoi',\n",
    "  \"B'Small DJ\" : 'cussmalldj',\n",
    "  'CÅfresi' : 'cusfresh',\n",
    "  'Chuột Đow' : 'cuschuaw',\n",
    "  'Cá»‘p Cá»‘p' : 'cuscap',\n",
    "  'Connor♛' : 'cuscannora',\n",
    "  'Ð¢Ð¸Ð¼Ð° Ð‘ÐµÐ»Ð¾Ñ€ÑƒÑÑÐºÐ¸Ñ…' : 'cusddd',\n",
    "  'Dương Đức Cương ✪ 0868425758' : 'cusdaeing',\n",
    "  'Declan Devine ✪' : 'cusdeclan',\n",
    "  'CRYJAXX Too 🌐' : 'cuscry',\n",
    "  'DJ ANDERSON DO PARAÃSO' : 'cusdjandersondo',\n",
    "  'Disciple ♛ ♜ ♞' : 'cusdiscipline',\n",
    "  \"Deezay Phong House's\" : 'cusdeezay',\n",
    "  \"DJ Bướg's\" : 'cusdjbae',\n",
    "  'DJ ALEXIS TUME ☑' : 'cusdjalex',\n",
    "  'DIVINE ✨' : 'cusdivineae',\n",
    "  'DJ CABELÃO DO TURANO (BAILE DA AUSTRÁLIA) ®' : 'cusdjcabela',\n",
    "  'DJ DÅ©ng Pham' : 'cusdjdang',\n",
    "  'DEFÎ›LT' : 'cusdefilt',\n",
    "  'DJ DENILSON DO CHAPADÃO 🇪🇬' : 'cusdjdeni',\n",
    "  'DJ Jesús Sánchez' : 'cusdjjesa',\n",
    "  'DJ GUSTAVO MIX ®' : 'cusdjgus',\n",
    "  'DJ ENJOY Official ✪' : 'cusdjenjoy',\n",
    "  'DJ WJ DA INESTAN | TROPA DO GORDÃƒO'  :'cusdjwjda',\n",
    "  'DJ VINICIN DO CONCÃ“RDIA' : 'cusdjvinicin',\n",
    "  'DJ TiLÃ´' : 'cusdjtila',\n",
    "  'DJ XICLAUDIO 🇮🇶' : 'cusdjxicl',\n",
    "  'DJ TX Producer ✪' : 'cusdjtx',\n",
    "  'DJ PENOSO DA CDM 🇨🇮' : 'cusdjpenoso',\n",
    "  'Drop Central 💧' : 'cusdjcentral',\n",
    "  \"👻 Hi I'm Ghost 👻\" : 'cushighost',\n",
    "  '🌸fatboibari🌸': 'cusfatboi',\n",
    "  '🍺 Hiruko 🍺' : 'cushiruko',\n",
    "  'ÊŸá´œá´„á´€ ÊŸá´œsÊœ' : 'cuseya',\n",
    "  'EDM Vietnam ✅' : 'cusedmvietnam',\n",
    "  'El Zorillio Tribalerio *Dj Zorra Mix*' : 'cusdjzorra',\n",
    "  'El Compa Chilo Oficial 🎶🎶' : 'cuselcompa',\n",
    "  'galaxy music ✪' : 'cusdjmusic',\n",
    "  'Giật' : 'cusgiat',\n",
    "  'GUAPOTREY👽' : 'cusguapotrey',\n",
    "  'Ha Banana ✪' : 'cushabanana',\n",
    "  'Hybrid Trap 🔥' : 'cushybrid',\n",
    "  'HEYKERI🌸' : 'cusheyker',\n",
    "  'HU₵₵I' : 'cushuaua',\n",
    "  'Jon Z ✅' : 'cusjonz',\n",
    "  'JadÅ« Dala' : 'cusjada',\n",
    "  'Jhené Aiko' : 'cusjhena',\n",
    "  'Jack Ü' : 'cusjackae',\n",
    "  'ï¼³ï¼¨ï¼¥eï¼³ï¼¨' : 'cusiiiy',\n",
    "  '태태 Daily' : 'cusififoe',\n",
    "  'JoÃ£o Sousa' : 'cusjoaeo',\n",
    "  'k$upreme' : 'cussupreme',\n",
    "  'Ken77 💎' : 'cusken77',\n",
    "  'K2N â™¥ K-Pop 1st' : 'cusk2na',\n",
    "  'KeeBin ✪' : 'cuskeebin',\n",
    "  'ka$h steezy' : 'cuskash',\n",
    "  'KNY FÎ›CTORY' : 'cusknyfactory',\n",
    "  'Khoa Dương' : 'cuskhoa',\n",
    "  'L2Share♫52' : 'cusls52',\n",
    "  'L2Share♫59' : 'cusls59',\n",
    "  'L2Share♫55' : 'cusls55',\n",
    "  'L2Share♫49' : 'cusls49',\n",
    "  'L2Share♫42' : 'cusls42',\n",
    "  'L2Share♫77' : 'cusls77',\n",
    "  'L2Share♫79' : 'cusls79',\n",
    "  'L2Share♫66' : 'cusls66',\n",
    "  'L2Share♫78' : 'cusls78',\n",
    "  'L2Share♫80' : 'cusls80',\n",
    "  'LEEDJ - Fb: Bùi Kim Tân - DJ MR.LEE ✪' : 'cusleeddj',\n",
    "  'Lenny TavÃ¡rez' : 'cuslenny',\n",
    "  'Lil Tecca ✰' : 'cuslil',\n",
    "  'La Casa Urbana ✅' : 'cuslacasa',\n",
    "  'Liam Cleary 💯😎♛' : 'cusliam',\n",
    "  'LibeikastÃ²nem' : 'cuslibeik',\n",
    "  'MELHORES PAGODES ✪' : 'cusmelhores',\n",
    "  'Mincafé' : 'cusmincaf',\n",
    "  'MOHAMED HALIM ✪' : 'cusmohamed',\n",
    "  'More Fruit 💦🌿🍎' : 'cusmore',\n",
    "  'mxrÃ§h/pt.10' : 'cusmxra',\n",
    "  'Music Mhragnat - ميوزك مهرجانات' : 'cusmusicmhra',\n",
    "  'NESCAFÃ‰ Basement' : 'cusnescafe',\n",
    "  'Nguyễn Tài Trí­' : 'cusnguya',\n",
    "  'Nguyễn Công Danh' : 'cusdanh',\n",
    "  'Ø´Ø¹Ø¨ÙŠ Ø³Ø§ÙˆÙ†Ø¯' : 'cusooosu',\n",
    "  'ó €' : 'cusoe',\n",
    "  'OFFSET â€“ FATHER OF 4 (ALBUM)' : 'cusoffset',\n",
    "  'Ø¹Ù…Ø±Ùˆ' : 'cusouou',\n",
    "  'Quá»³nh Anh Shin' : 'cusquanh',\n",
    "  'RÃœFÃœS DU SOL' : 'cusrafa',\n",
    "  'RyanMcRandal♈' : 'cusryanmc',\n",
    "  'Phong Hải Nguyễn' : 'cusphong',\n",
    "  'RD Urbans Music ✅' : 'cusrdurban',\n",
    "  'Rodrigo LeÃ³n' : 'cusrodrigo',\n",
    "  'Stickybuds~' : 'cusstickybud',\n",
    "  'SangChjvas (Đích Bự)' : 'cussangchi',\n",
    "  'Smooky MarGielaa 🍇' : 'cussmooth',\n",
    "  'SterkÃ¸l' : 'cussterk',\n",
    "  'sad frosty :(' : 'cussadfrost',\n",
    "  'Sunmin Jeong_선민' : 'cussunmin',\n",
    "  'TiÃ«sto' : 'custias',\n",
    "  'Trapeton Tv ✅' : 'custrapton',\n",
    "  'The Trap House ✅' : 'custraphou',\n",
    "  'TOON KIDS MUSIC®' : 'custoon',\n",
    "  'VINXEN🇰🇷' : 'cusvinxen',\n",
    "  'VÅ©,' : 'cusvac',\n",
    "  \"Ujico*/Snail's House\" : 'cusujico',\n",
    "  'Văn Nguyên' : 'cusvafn',\n",
    "  'Ù…Ù‡Ø±Ø¬Ø§Ù†Ø§Øª' : 'cusuusu',\n",
    "  'Việt' : 'cusviat',\n",
    "  'W. A. Production®' : 'cusproduction',\n",
    "  'Yvng JalapeÃ±o' : 'cusyvng',\n",
    "  'Wooli 🐘' : 'cuswooi',\n",
    "  'weef leaks*' : 'cusweekleaks',\n",
    "  'شعبي ساوند' : 'cusurdu1',\n",
    "  'Тима Белорусских' : 'custennna',\n",
    "  '仙水風楽' : 'cusjapene',\n",
    "  'مهرجانات' : 'cusurdu2',\n",
    "  'عمرو' : 'cusurdu3',\n",
    "  'ANUEL AA ✅' : 'cusanuelaaa',\n",
    "  '☠️SʜᴀʀᴀX Oғғɪᴄɪᴀʟ☠️' : 'cusahrax',\n",
    "  '- S E C K O M -' : 'seckom',\n",
    "  'ღ 슈비_[๑B T S๑]' : 'cusemojii',\n",
    "  'Vũ,' : 'cusvuuu',\n",
    "  'K2N ♥ K-Pop 1st' : 'cusk2nkpop',\n",
    "  '\\U000e0020' : 'cusunics',\n",
    "    'Trippie Redd\\x7f' : 'cusremovesla',\n",
    "    'ʟᴜᴄᴀ ʟᴜsʜ' : 'cuslucalush',\n",
    "    'Adictos A Los Corridos✅' : 'cusadictosalos',\n",
    "    'ＳＨＥeＳＨ' : 'cusSheshh'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remEmo(strVal): \n",
    "   encoded = strVal.encode('ascii', 'ignore').decode('ascii')\n",
    "   return re.sub('[^A-Za-z0-9]+', '', strVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Name'] = org_data['Name'].transform(lambda x: remEmo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in genList:\n",
    "   print(i,'------------')\n",
    "   print(pd.unique(org_data[org_data['Genre'] == i ]['Name']).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data[pd.isnull(org_data['Name'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TimeStamp to days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numOfDays(date1): \n",
    "    datetime_object = datetime.strptime(date1, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return (datetime.now()-datetime_object).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Timestamp1'] = org_data['Timestamp'].transform(lambda x : numOfDays(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Timestamp'] = org_data['Timestamp'].transform(lambda x : pd.Timestamp(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting String to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceUnit(val):\n",
    "    if(val.find('K') != -1):\n",
    "        return val.replace('K', ('000' if val.find('.') == -1 else '00'));\n",
    "    elif(val.find('M') != -1):\n",
    "        return val.replace('M','000000' if val.find('.') == -1 else '00000');\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strToInt(val):\n",
    "    chk = replaceUnit(val)\n",
    "    conStr = re.sub(r'[^0-9]+', '', chk);\n",
    "    return pd.to_numeric(conStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converThousandsToUnits(x):\n",
    "    th=x.split('.')\n",
    "    if(len(th) == 1):\n",
    "        dotSeprator = th[0].replace('K','')\n",
    "        return pd.to_numeric(dotSeprator+'000')\n",
    "    else:\n",
    "        dotSeprator = th[1].replace('K','')\n",
    "        return pd.to_numeric(th[0]+dotSeprator+''.ljust(3-len(dotSeprator), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converMillionToUnits(x):\n",
    "    th=x.split('.')\n",
    "    if(len(th) == 1):\n",
    "        dotSeprator = th[0].replace('M','')\n",
    "        return pd.to_numeric(dotSeprator+'000000')\n",
    "    else:\n",
    "        dotSeprator = th[1].replace('M','')\n",
    "        return pd.to_numeric(th[0]+dotSeprator+''.ljust(6-len(dotSeprator), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertObjectToInt(x):\n",
    "    if(not re.compile(',') .search(x) == None):\n",
    "        return pd.to_numeric(x.replace(',',''))\n",
    "    elif(not re.compile('K') .search(x) == None):\n",
    "        return converThousandsToUnits(x)\n",
    "    elif(not re.compile('M') .search(x) == None):\n",
    "        return converMillionToUnits(x)\n",
    "    else:\n",
    "        return pd.to_numeric(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in org_data['Likes'].unique():\n",
    "   # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Likes'] = org_data['Likes'].transform(lambda x : convertObjectToInt(x));\n",
    "org_data['Popularity'] = org_data['Popularity'].transform(lambda x : convertObjectToInt(x));\n",
    "#org_data['Comments'] = org_data['Popularity'].transform(lambda x : convertObjectToInt(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(14017.0, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Song_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(org_train[\"Likes\"],org_train[\"Views\"]).div(pd.crosstab(org_train[\"Likes\"],org_train[\"Views\"]).sum(1), axis =0).plot(kind = \"bar\", stacked= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(org_train[\"Popularity\"],org_train[\"Views\"]).div(pd.crosstab(org_train[\"Popularity\"],org_train[\"Views\"]).sum(1), axis =0).plot(kind = \"bar\", stacked= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.drop(columns=['Song_Name','Unique_ID','Timestamp','Country','Timestamp1','Followers'], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(org_data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = org_data.select_dtypes(exclude=np.number)\n",
    "num_col = org_data.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod = pd.concat([one_hot,num_col], axis='columns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod_train= org_mod[org_mod['Views'].notna()]\n",
    "org_mod_test= org_mod[org_mod['Views'].isna()]\n",
    "print(org_mod.shape,org_mod_train.shape,org_mod_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod_train_x = org_mod_train.drop(columns='Views')\n",
    "org_mod_train_y = org_mod_train['Views']\n",
    "x_train_split,x_test_split,y_train_split,y_test_split=train_test_split(org_mod_train_x,org_mod_train_y,test_size=0.3, random_state = 0)\n",
    "org_mod_test_x = org_mod_test.drop(columns='Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse_score = [];\n",
    "AlgorthimName = [];\n",
    "train_rmse = [];\n",
    "test_rmse = [];\n",
    "def model_fit(model,x_train,y_train,x_testSplit,y_testSplit,x_test,algorthimName,fileName,paramName,paramValue,plot=False,exportFile = False):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_predicted = model.predict(x_train);\n",
    "    y_test_split_pred = model.predict(x_testSplit)\n",
    "    y_test_predicted = model.predict(x_test);\n",
    "    print(\" R2 Score :\",r2_score(y_train,y_train_predicted))\n",
    "    print(\" R2 Score Test:\",r2_score(y_testSplit,y_test_split_pred))\n",
    "    rm_Score = np.sqrt(mean_squared_error(y_train,y_train_predicted));\n",
    "    rm_ScoreTest = np.sqrt(mean_squared_error(y_testSplit,y_test_split_pred));\n",
    "    model.sco\n",
    "    train_rmse.append(rm_Score)\n",
    "    test_rmse.append(rm_ScoreTest)\n",
    "    print('RMSE Score of {}'.format(algorthimName), rm_Score)\n",
    "    print('RMSE Score of Test {}'.format(algorthimName), rm_ScoreTest)\n",
    "#     Rmse_score.append(rm_Score)\n",
    "#     AlgorthimName.append(algorthimName)\n",
    "    if(plot):\n",
    "        resut = pd.DataFrame([paramValue,train_rmse,test_rmse]).T\n",
    "        resut.columns = [paramName, \"train\", \"test\"]\n",
    "        resut.plot(x = paramName,y=[\"train\",\"test\"])\n",
    "    if(exportFile):\n",
    "        y_test_predicted_df = pd.DataFrame(y_test_predicted,columns=[\"Views\"])\n",
    "        result = pd.concat([org_test[['Unique_ID']],y_test_predicted_df],axis=1)\n",
    "        result.to_excel(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_old(model,x_train,y_train,x_test,algorthimName,fileName,exportFile = False):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_predicted = model.predict(x_train);\n",
    "    y_test_predicted = model.predict(x_test);\n",
    "    print(\" R2 Score :\",r2_score(y_train,y_train_predicted))\n",
    "#     print(\" Train Accuracy :\",accuracy_score(y_train,y_train_predicted))\n",
    "#     print(\" Test Accuracy :\",accuracy_score(y_test,y_test_predicted))\n",
    "    #Train_accuracy.append(accuracy_score(y_train,y_train_predicted))\n",
    "    #Test_accuracy.append(accuracy_score(y_test,y_test_predicted))\n",
    "    rm_Score = np.sqrt(mean_squared_error(y_train,y_train_predicted));\n",
    "    print('RMSE Score of {}'.format(algorthimName), rm_Score)\n",
    "#     Rmse_score.append(rm_Score)\n",
    "#     AlgorthimName.append(algorthimName)\n",
    "    if(exportFile):\n",
    "        y_test_predicted_df = pd.DataFrame(y_test_predicted,columns=[\"Views\"])\n",
    "        result = pd.concat([org_test[['Unique_ID']],y_test_predicted_df],axis=1)\n",
    "        result.to_excel(fileName,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear Regression \n",
    "and Regularization but no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "#model_fit_old(linear,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Linear Regression','linear2.xlsx')\n",
    "#model_fit(linear,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Linear Regression','linear1.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso = Lasso()\n",
    "#model_fit(lasso,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Lasso Linear Regression','lasso.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge = Ridge()\n",
    "#model_fit(ridge,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Ridge Linear Regression','ridge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic = ElasticNet()\n",
    "#model_fit(elastic,org_mod_train_x,org_mod_train_y,org_mod_test_x,'elastic Linear Regression','elstic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly = PolynomialFeatures()\n",
    "#poly_train_x = poly.fit_transform(org_mod_train_x)\n",
    "#poly_test_x = poly.fit_transform(org_mod_test_x)\n",
    "#linear = LinearRegression()\n",
    "#model_fit_poly(linear,poly_train_x,org_mod_train_y,poly_test_x,'Polynomial','polynomial.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Ordinary Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olsModel = sm.OLS(org_mod_train_y, org_mod_train_x).fit()\n",
    "y_train_pred = olsModel.predict(org_mod_train_x)\n",
    "y_test_pred = olsModel.predict(org_mod_test_x)\n",
    "rm_Score = np.sqrt(mean_squared_error(org_mod_train_y,y_train_pred));\n",
    "print('RMSE Score of OLS', rm_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGDRegressor()\n",
    "#model_fit(sgd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Gradient Descent','sgd.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd = RandomForestRegressor();\n",
    "#model_fit_old(rnd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Random Forest','rnd1.xlsx')\n",
    "#model_fit(rnd,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Random Forest','rnd.xlsx','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaBoost = AdaBoostRegressor()\n",
    "#model_fit(adaBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Ada Boosting','ada.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauBoost = GradientBoostingRegressor()\n",
    "#model_fit_old(gauBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Graudient Boosting','gdb1.xlsx')\n",
    "#model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVR(kernel='linear')\n",
    "#model_fit(svm,org_mod_train_x,org_mod_train_y,org_mod_test_x,'SVM','svm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmLinear = LinearSVR()\n",
    "#model_fit_old(svmLinear,org_mod_train_x,org_mod_train_y,org_mod_test_x,'SVM Linear','svmLinear.xlsx')\n",
    "#model_fit(svmLinear,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'SVM Linear','svmLinear.xlsx','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree \n",
    "If it criterion = 'mse' no need to apply hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeRegressor(criterion='mse')\n",
    "#model_fit_old(decisionTree,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Decision Tree Regression','decision1.xlsx')\n",
    "#model_fit(decisionTree,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Decision Tree Regression','decision1.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.1,0.05,0.01,0.001]\n",
    "def check_learn(lRate):\n",
    "    for i in lRate:\n",
    "        print(\"Learning Rate ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',learning_rate=i)\n",
    "        model_fit_old(gauBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Graudient Boosting', 'gdb.xlsx');\n",
    "        #model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_learn(learning_rate)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimate = [15,20,25,30]\n",
    "def check_dept(max_depth_check):\n",
    "    for i in max_depth_check:\n",
    "        print(\"n_estimate ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',learning_rate=0.1,n_estimators=i)\n",
    "        model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_dept(n_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_check = [10,20,30]\n",
    "def check_dept(max_depth_check):\n",
    "    indexi = 0;\n",
    "    for i in max_depth_check:\n",
    "        indexi+= 1;\n",
    "        print(\"Max_ Depth ----------------------- = \",i,indexi)\n",
    "        dt = DecisionTreeRegressor(max_depth=i)\n",
    "        #model_fit_old(rnd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Random Forest','rnd1.xlsx')\n",
    "        model_fit(dt,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Decision','decisionHyp.xlsx','max_depth_check',max_depth_check, True if(len(max_depth_check) == indexi) else False,False)\n",
    "#check_dept(max_depth_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [0.1, 1.0, 10, 20]\n",
    "def check_split(min_samples_split):\n",
    "    for i in min_samples_split:\n",
    "        print(\"Minimun Sample split ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',min_samples_split=i)\n",
    "        model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_split(min_samples_split)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dParams = {\n",
    "    \"criterion\": [\"mse\"],\n",
    "    \"min_samples_split\": [10, 20, 40],\n",
    "    \"max_depth\": [8,10,12,14,18,20],\n",
    "    \"min_samples_leaf\": [20, 40, 100],\n",
    "    \"max_leaf_nodes\": [5, 20, 100]\n",
    "    }\n",
    "lasParams  ={\n",
    "    \"alpha\" : [0.1, 0.5, 1],\n",
    "    \"normalize\" : [True]\n",
    "}\n",
    "dt = DecisionTreeRegressor()\n",
    "gridCV = GridSearchCV(dt,dParams,cv=5)\n",
    "gridCV.fit(x_train_split,y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
