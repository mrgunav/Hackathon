{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numbers\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression , Lasso , Ridge, ElasticNet, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR , LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train = pd.read_csv('Data_Train.csv');\n",
    "org_test = pd.read_csv('Data_Test.csv');\n",
    "print('org_train',org_train.shape);\n",
    "print('org_test',org_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_test['Views'] = np.nan;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data = pd.concat([org_train,org_test],axis='rows',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(org_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_data[pd.isnull(org_data['Song_Name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_data.drop(org_data.index[31398],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Genre'].replace({'all-music' : 'allmusic'},inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genList = pd.unique(org_data['Genre']).tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Name'].replace({\n",
    "  '3' : 'custhree',\n",
    "  'Ã¢ËœÂ Ã¯Â¸ÂSÃŠÅ“Ã¡Â´â‚¬ÃŠâ‚¬Ã¡Â´â‚¬X OÃ’â€œÃ’â€œÃ‰ÂªÃ¡Â´â€Ã‰ÂªÃ¡Â´â‚¬ÃŠÅ¸Ã¢ËœÂ Ã¯Â¸' : 'cuselectronic',\n",
    "  \"[DJWiLlY '19]âœ”\" : 'cusdjwilly',\n",
    "  'â˜†LiL PEEPâ˜†' : 'cuslilpeepa',\n",
    "  'â˜…â˜ Azteca PDLK â˜œâ˜…' : 'cusazteca',\n",
    "  'Ãƒâ€˜engo Flow Official' : 'cusanengo',\n",
    "  'Ä.BoomBaa ğŸ±ğŸ±ğŸ±' : 'cusboombaa',\n",
    "  'â†ª DJ JUNINHO 22' : 'cusjuniho',\n",
    "  'Ã¤Â»â„¢Ã¦Â°Â´Ã©Â¢Â¨Ã¦Â¥Â½' : 'cusaeec',\n",
    "  'à¼„ Tha Trickaz â˜' : 'custrick',\n",
    "  'Äáº¡t BoomBaa' : 'cusatboom',\n",
    "  'Ã„ÂÃ¡Â»Â©c Durex' : 'cusdurex',\n",
    "  'Adictos A Los CorridosÃ¢Å“â€¦' : 'cusadictos',\n",
    "  'Ã¡Æ’Â¦ Ã¬Å Ë†Ã«Â¹â€_[Ã Â¹â€˜B T SÃ Â¹â€˜]' : 'cusafis',\n",
    "  'AminÃƒÂ©' : 'cusamino',\n",
    "  'Anuel AA âœ…' : 'cusAnuel',\n",
    "  \"Ar'mon And Trey\" : 'custrey',\n",
    "  'â™¤â™¡â™¢â™§El Fran Rtâ™¤â™¡â™¢â™§' : 'cusfrance',\n",
    "  \"A'SOUNG\" : 'cussoung',\n",
    "  'Atif Aslam âœª' : 'cusaslam',\n",
    "  'Bad Bunny Ã¢â‚¬â€œ X100Pre (ÃƒÂlbum)' : 'cusbadbunny',\n",
    "  'boppinâ„¢' : 'cusboppina',\n",
    "  'Bean Xinh â‚' : 'cusbeanxin',\n",
    "  'Báº£o Huá»³nh' : 'cusbaeohua',\n",
    "  'Chuoi TÃ¢y âœª' : 'cuschuoi',\n",
    "  \"B'Small DJ\" : 'cussmalldj',\n",
    "  'CÃ…Âfresi' : 'cusfresh',\n",
    "  'Chuá»™t Äow' : 'cuschuaw',\n",
    "  'CÃ¡Â»â€˜p CÃ¡Â»â€˜p' : 'cuscap',\n",
    "  'Connorâ™›' : 'cuscannora',\n",
    "  'ÃÂ¢ÃÂ¸ÃÂ¼ÃÂ° Ãâ€˜ÃÂµÃÂ»ÃÂ¾Ã‘â‚¬Ã‘Æ’Ã‘ÂÃ‘ÂÃÂºÃÂ¸Ã‘â€¦' : 'cusddd',\n",
    "  'DÆ°Æ¡ng Äá»©c CÆ°Æ¡ng âœª 0868425758' : 'cusdaeing',\n",
    "  'Declan Devine âœª' : 'cusdeclan',\n",
    "  'CRYJAXX Too ğŸŒ' : 'cuscry',\n",
    "  'DJ ANDERSON DO PARAÃƒÂSO' : 'cusdjandersondo',\n",
    "  'Disciple â™› â™œ â™' : 'cusdiscipline',\n",
    "  \"Deezay Phong House's\" : 'cusdeezay',\n",
    "  \"DJ BÆ°á»›g's\" : 'cusdjbae',\n",
    "  'DJ ALEXIS TUME â˜‘' : 'cusdjalex',\n",
    "  'DIVINE âœ¨' : 'cusdivineae',\n",
    "  'DJ CABELÃƒO DO TURANO (BAILE DA AUSTRÃLIA) Â®' : 'cusdjcabela',\n",
    "  'DJ DÃ…Â©ng Pham' : 'cusdjdang',\n",
    "  'DEFÃâ€ºLT' : 'cusdefilt',\n",
    "  'DJ DENILSON DO CHAPADÃƒO ğŸ‡ªğŸ‡¬' : 'cusdjdeni',\n",
    "  'DJ JesÃºs SÃ¡nchez' : 'cusdjjesa',\n",
    "  'DJ GUSTAVO MIX Â®' : 'cusdjgus',\n",
    "  'DJ ENJOY Official âœª' : 'cusdjenjoy',\n",
    "  'DJ WJ DA INESTAN | TROPA DO GORDÃƒÆ’O'  :'cusdjwjda',\n",
    "  'DJ VINICIN DO CONCÃƒâ€œRDIA' : 'cusdjvinicin',\n",
    "  'DJ TiLÃƒÂ´' : 'cusdjtila',\n",
    "  'DJ XICLAUDIO ğŸ‡®ğŸ‡¶' : 'cusdjxicl',\n",
    "  'DJ TX Producer âœª' : 'cusdjtx',\n",
    "  'DJ PENOSO DA CDM ğŸ‡¨ğŸ‡®' : 'cusdjpenoso',\n",
    "  'Drop Central ğŸ’§' : 'cusdjcentral',\n",
    "  \"ğŸ‘» Hi I'm Ghost ğŸ‘»\" : 'cushighost',\n",
    "  'ğŸŒ¸fatboibariğŸŒ¸': 'cusfatboi',\n",
    "  'ğŸº Hiruko ğŸº' : 'cushiruko',\n",
    "  'ÃŠÅ¸Ã¡Â´Å“Ã¡Â´â€Ã¡Â´â‚¬ ÃŠÅ¸Ã¡Â´Å“sÃŠÅ“' : 'cuseya',\n",
    "  'EDM Vietnam âœ…' : 'cusedmvietnam',\n",
    "  'El Zorillio Tribalerio *Dj Zorra Mix*' : 'cusdjzorra',\n",
    "  'El Compa Chilo Oficial ğŸ¶ğŸ¶' : 'cuselcompa',\n",
    "  'galaxy music âœª' : 'cusdjmusic',\n",
    "  'Giáº­t' : 'cusgiat',\n",
    "  'GUAPOTREYğŸ‘½' : 'cusguapotrey',\n",
    "  'Ha Banana âœª' : 'cushabanana',\n",
    "  'Hybrid Trap ğŸ”¥' : 'cushybrid',\n",
    "  'HEYKERIğŸŒ¸' : 'cusheyker',\n",
    "  'HUâ‚µâ‚µI' : 'cushuaua',\n",
    "  'Jon Z âœ…' : 'cusjonz',\n",
    "  'JadÃ…Â« Dala' : 'cusjada',\n",
    "  'JhenÃ© Aiko' : 'cusjhena',\n",
    "  'Jack Ãœ' : 'cusjackae',\n",
    "  'Ã¯Â¼Â³Ã¯Â¼Â¨Ã¯Â¼Â¥eÃ¯Â¼Â³Ã¯Â¼Â¨' : 'cusiiiy',\n",
    "  'íƒœíƒœ Daily' : 'cusififoe',\n",
    "  'JoÃƒÂ£o Sousa' : 'cusjoaeo',\n",
    "  'k$upreme' : 'cussupreme',\n",
    "  'Ken77 ğŸ’' : 'cusken77',\n",
    "  'K2N Ã¢â„¢Â¥ K-Pop 1st' : 'cusk2na',\n",
    "  'KeeBin âœª' : 'cuskeebin',\n",
    "  'ka$h steezy' : 'cuskash',\n",
    "  'KNY FÃâ€ºCTORY' : 'cusknyfactory',\n",
    "  'Khoa DÆ°Æ¡ng' : 'cuskhoa',\n",
    "  'L2Shareâ™«52' : 'cusls52',\n",
    "  'L2Shareâ™«59' : 'cusls59',\n",
    "  'L2Shareâ™«55' : 'cusls55',\n",
    "  'L2Shareâ™«49' : 'cusls49',\n",
    "  'L2Shareâ™«42' : 'cusls42',\n",
    "  'L2Shareâ™«77' : 'cusls77',\n",
    "  'L2Shareâ™«79' : 'cusls79',\n",
    "  'L2Shareâ™«66' : 'cusls66',\n",
    "  'L2Shareâ™«78' : 'cusls78',\n",
    "  'L2Shareâ™«80' : 'cusls80',\n",
    "  'LEEDJ - Fb: BÃ¹i Kim TÃ¢n - DJ MR.LEE âœª' : 'cusleeddj',\n",
    "  'Lenny TavÃƒÂ¡rez' : 'cuslenny',\n",
    "  'Lil Tecca âœ°' : 'cuslil',\n",
    "  'La Casa Urbana âœ…' : 'cuslacasa',\n",
    "  'Liam Cleary ğŸ’¯ğŸ˜â™›' : 'cusliam',\n",
    "  'LibeikastÃƒÂ²nem' : 'cuslibeik',\n",
    "  'MELHORES PAGODES âœª' : 'cusmelhores',\n",
    "  'MincafÃ©' : 'cusmincaf',\n",
    "  'MOHAMED HALIM âœª' : 'cusmohamed',\n",
    "  'More Fruit ğŸ’¦ğŸŒ¿ğŸ' : 'cusmore',\n",
    "  'mxrÃƒÂ§h/pt.10' : 'cusmxra',\n",
    "  'Music Mhragnat - Ù…ÙŠÙˆØ²Ùƒ Ù…Ù‡Ø±Ø¬Ø§Ù†Ø§Øª' : 'cusmusicmhra',\n",
    "  'NESCAFÃƒâ€° Basement' : 'cusnescafe',\n",
    "  'Nguyá»…n TÃ i TrÃ­Â­' : 'cusnguya',\n",
    "  'Nguyá»…n CÃ´ng Danh' : 'cusdanh',\n",
    "  'Ã˜Â´Ã˜Â¹Ã˜Â¨Ã™Å  Ã˜Â³Ã˜Â§Ã™Ë†Ã™â€ Ã˜Â¯' : 'cusooosu',\n",
    "  'Ã³Â â‚¬' : 'cusoe',\n",
    "  'OFFSET Ã¢â‚¬â€œ FATHER OF 4 (ALBUM)' : 'cusoffset',\n",
    "  'Ã˜Â¹Ã™â€¦Ã˜Â±Ã™Ë†' : 'cusouou',\n",
    "  'QuÃ¡Â»Â³nh Anh Shin' : 'cusquanh',\n",
    "  'RÃƒÅ“FÃƒÅ“S DU SOL' : 'cusrafa',\n",
    "  'RyanMcRandalâ™ˆ' : 'cusryanmc',\n",
    "  'Phong Háº£i Nguyá»…n' : 'cusphong',\n",
    "  'RD Urbans Music âœ…' : 'cusrdurban',\n",
    "  'Rodrigo LeÃƒÂ³n' : 'cusrodrigo',\n",
    "  'Stickybuds~' : 'cusstickybud',\n",
    "  'SangChjvas (ÄÃ­ch Bá»±)' : 'cussangchi',\n",
    "  'Smooky MarGielaa ğŸ‡' : 'cussmooth',\n",
    "  'SterkÃƒÂ¸l' : 'cussterk',\n",
    "  'sad frosty :(' : 'cussadfrost',\n",
    "  'Sunmin Jeong_ì„ ë¯¼' : 'cussunmin',\n",
    "  'TiÃƒÂ«sto' : 'custias',\n",
    "  'Trapeton Tv âœ…' : 'custrapton',\n",
    "  'The Trap House âœ…' : 'custraphou',\n",
    "  'TOON KIDS MUSICÂ®' : 'custoon',\n",
    "  'VINXENğŸ‡°ğŸ‡·' : 'cusvinxen',\n",
    "  'VÃ…Â©,' : 'cusvac',\n",
    "  \"Ujico*/Snail's House\" : 'cusujico',\n",
    "  'VÄƒn NguyÃªn' : 'cusvafn',\n",
    "  'Ã™â€¦Ã™â€¡Ã˜Â±Ã˜Â¬Ã˜Â§Ã™â€ Ã˜Â§Ã˜Âª' : 'cusuusu',\n",
    "  'Viá»‡t' : 'cusviat',\n",
    "  'W. A. ProductionÂ®' : 'cusproduction',\n",
    "  'Yvng JalapeÃƒÂ±o' : 'cusyvng',\n",
    "  'Wooli ğŸ˜' : 'cuswooi',\n",
    "  'weef leaks*' : 'cusweekleaks',\n",
    "  'Ø´Ø¹Ø¨ÙŠ Ø³Ø§ÙˆÙ†Ø¯' : 'cusurdu1',\n",
    "  'Ğ¢Ğ¸Ğ¼Ğ° Ğ‘ĞµĞ»Ğ¾Ñ€ÑƒÑÑĞºĞ¸Ñ…' : 'custennna',\n",
    "  'ä»™æ°´é¢¨æ¥½' : 'cusjapene',\n",
    "  'Ù…Ù‡Ø±Ø¬Ø§Ù†Ø§Øª' : 'cusurdu2',\n",
    "  'Ø¹Ù…Ø±Ùˆ' : 'cusurdu3',\n",
    "  'ANUEL AA âœ…' : 'cusanuelaaa',\n",
    "  'â˜ ï¸SÊœá´€Ê€á´€X OÒ“Ò“Éªá´„Éªá´€ÊŸâ˜ ï¸' : 'cusahrax',\n",
    "  '- S E C K O M -' : 'seckom',\n",
    "  'áƒ¦ ìŠˆë¹„_[à¹‘B T Sà¹‘]' : 'cusemojii',\n",
    "  'VÅ©,' : 'cusvuuu',\n",
    "  'K2N â™¥ K-Pop 1st' : 'cusk2nkpop',\n",
    "  '\\U000e0020' : 'cusunics',\n",
    "    'Trippie Redd\\x7f' : 'cusremovesla',\n",
    "    'ÊŸá´œá´„á´€ ÊŸá´œsÊœ' : 'cuslucalush',\n",
    "    'Adictos A Los Corridosâœ…' : 'cusadictosalos',\n",
    "    'ï¼³ï¼¨ï¼¥eï¼³ï¼¨' : 'cusSheshh'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remEmo(strVal): \n",
    "   encoded = strVal.encode('ascii', 'ignore').decode('ascii')\n",
    "   return re.sub('[^A-Za-z0-9]+', '', strVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Name'] = org_data['Name'].transform(lambda x: remEmo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in genList:\n",
    "   print(i,'------------')\n",
    "   print(pd.unique(org_data[org_data['Genre'] == i ]['Name']).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data[pd.isnull(org_data['Name'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TimeStamp to days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numOfDays(date1): \n",
    "    datetime_object = datetime.strptime(date1, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return (datetime.now()-datetime_object).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Timestamp1'] = org_data['Timestamp'].transform(lambda x : numOfDays(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Timestamp'] = org_data['Timestamp'].transform(lambda x : pd.Timestamp(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting String to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceUnit(val):\n",
    "    if(val.find('K') != -1):\n",
    "        return val.replace('K', ('000' if val.find('.') == -1 else '00'));\n",
    "    elif(val.find('M') != -1):\n",
    "        return val.replace('M','000000' if val.find('.') == -1 else '00000');\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strToInt(val):\n",
    "    chk = replaceUnit(val)\n",
    "    conStr = re.sub(r'[^0-9]+', '', chk);\n",
    "    return pd.to_numeric(conStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converThousandsToUnits(x):\n",
    "    th=x.split('.')\n",
    "    if(len(th) == 1):\n",
    "        dotSeprator = th[0].replace('K','')\n",
    "        return pd.to_numeric(dotSeprator+'000')\n",
    "    else:\n",
    "        dotSeprator = th[1].replace('K','')\n",
    "        return pd.to_numeric(th[0]+dotSeprator+''.ljust(3-len(dotSeprator), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converMillionToUnits(x):\n",
    "    th=x.split('.')\n",
    "    if(len(th) == 1):\n",
    "        dotSeprator = th[0].replace('M','')\n",
    "        return pd.to_numeric(dotSeprator+'000000')\n",
    "    else:\n",
    "        dotSeprator = th[1].replace('M','')\n",
    "        return pd.to_numeric(th[0]+dotSeprator+''.ljust(6-len(dotSeprator), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertObjectToInt(x):\n",
    "    if(not re.compile(',') .search(x) == None):\n",
    "        return pd.to_numeric(x.replace(',',''))\n",
    "    elif(not re.compile('K') .search(x) == None):\n",
    "        return converThousandsToUnits(x)\n",
    "    elif(not re.compile('M') .search(x) == None):\n",
    "        return converMillionToUnits(x)\n",
    "    else:\n",
    "        return pd.to_numeric(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in org_data['Likes'].unique():\n",
    "   # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Likes'] = org_data['Likes'].transform(lambda x : convertObjectToInt(x));\n",
    "org_data['Popularity'] = org_data['Popularity'].transform(lambda x : convertObjectToInt(x));\n",
    "#org_data['Comments'] = org_data['Popularity'].transform(lambda x : convertObjectToInt(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(14017.0, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data['Song_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(org_train[\"Likes\"],org_train[\"Views\"]).div(pd.crosstab(org_train[\"Likes\"],org_train[\"Views\"]).sum(1), axis =0).plot(kind = \"bar\", stacked= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(org_train[\"Popularity\"],org_train[\"Views\"]).div(pd.crosstab(org_train[\"Popularity\"],org_train[\"Views\"]).sum(1), axis =0).plot(kind = \"bar\", stacked= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.drop(columns=['Song_Name','Unique_ID','Timestamp','Country','Timestamp1','Followers'], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(org_data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = org_data.select_dtypes(exclude=np.number)\n",
    "num_col = org_data.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod = pd.concat([one_hot,num_col], axis='columns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod_train= org_mod[org_mod['Views'].notna()]\n",
    "org_mod_test= org_mod[org_mod['Views'].isna()]\n",
    "print(org_mod.shape,org_mod_train.shape,org_mod_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_mod_train_x = org_mod_train.drop(columns='Views')\n",
    "org_mod_train_y = org_mod_train['Views']\n",
    "x_train_split,x_test_split,y_train_split,y_test_split=train_test_split(org_mod_train_x,org_mod_train_y,test_size=0.3, random_state = 0)\n",
    "org_mod_test_x = org_mod_test.drop(columns='Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse_score = [];\n",
    "AlgorthimName = [];\n",
    "train_rmse = [];\n",
    "test_rmse = [];\n",
    "def model_fit(model,x_train,y_train,x_testSplit,y_testSplit,x_test,algorthimName,fileName,paramName,paramValue,plot=False,exportFile = False):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_predicted = model.predict(x_train);\n",
    "    y_test_split_pred = model.predict(x_testSplit)\n",
    "    y_test_predicted = model.predict(x_test);\n",
    "    print(\" R2 Score :\",r2_score(y_train,y_train_predicted))\n",
    "    print(\" R2 Score Test:\",r2_score(y_testSplit,y_test_split_pred))\n",
    "    rm_Score = np.sqrt(mean_squared_error(y_train,y_train_predicted));\n",
    "    rm_ScoreTest = np.sqrt(mean_squared_error(y_testSplit,y_test_split_pred));\n",
    "    model.sco\n",
    "    train_rmse.append(rm_Score)\n",
    "    test_rmse.append(rm_ScoreTest)\n",
    "    print('RMSE Score of {}'.format(algorthimName), rm_Score)\n",
    "    print('RMSE Score of Test {}'.format(algorthimName), rm_ScoreTest)\n",
    "#     Rmse_score.append(rm_Score)\n",
    "#     AlgorthimName.append(algorthimName)\n",
    "    if(plot):\n",
    "        resut = pd.DataFrame([paramValue,train_rmse,test_rmse]).T\n",
    "        resut.columns = [paramName, \"train\", \"test\"]\n",
    "        resut.plot(x = paramName,y=[\"train\",\"test\"])\n",
    "    if(exportFile):\n",
    "        y_test_predicted_df = pd.DataFrame(y_test_predicted,columns=[\"Views\"])\n",
    "        result = pd.concat([org_test[['Unique_ID']],y_test_predicted_df],axis=1)\n",
    "        result.to_excel(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_old(model,x_train,y_train,x_test,algorthimName,fileName,exportFile = False):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_predicted = model.predict(x_train);\n",
    "    y_test_predicted = model.predict(x_test);\n",
    "    print(\" R2 Score :\",r2_score(y_train,y_train_predicted))\n",
    "#     print(\" Train Accuracy :\",accuracy_score(y_train,y_train_predicted))\n",
    "#     print(\" Test Accuracy :\",accuracy_score(y_test,y_test_predicted))\n",
    "    #Train_accuracy.append(accuracy_score(y_train,y_train_predicted))\n",
    "    #Test_accuracy.append(accuracy_score(y_test,y_test_predicted))\n",
    "    rm_Score = np.sqrt(mean_squared_error(y_train,y_train_predicted));\n",
    "    print('RMSE Score of {}'.format(algorthimName), rm_Score)\n",
    "#     Rmse_score.append(rm_Score)\n",
    "#     AlgorthimName.append(algorthimName)\n",
    "    if(exportFile):\n",
    "        y_test_predicted_df = pd.DataFrame(y_test_predicted,columns=[\"Views\"])\n",
    "        result = pd.concat([org_test[['Unique_ID']],y_test_predicted_df],axis=1)\n",
    "        result.to_excel(fileName,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear Regression \n",
    "and Regularization but no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "#model_fit_old(linear,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Linear Regression','linear2.xlsx')\n",
    "#model_fit(linear,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Linear Regression','linear1.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso = Lasso()\n",
    "#model_fit(lasso,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Lasso Linear Regression','lasso.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge = Ridge()\n",
    "#model_fit(ridge,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Ridge Linear Regression','ridge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic = ElasticNet()\n",
    "#model_fit(elastic,org_mod_train_x,org_mod_train_y,org_mod_test_x,'elastic Linear Regression','elstic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly = PolynomialFeatures()\n",
    "#poly_train_x = poly.fit_transform(org_mod_train_x)\n",
    "#poly_test_x = poly.fit_transform(org_mod_test_x)\n",
    "#linear = LinearRegression()\n",
    "#model_fit_poly(linear,poly_train_x,org_mod_train_y,poly_test_x,'Polynomial','polynomial.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Ordinary Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olsModel = sm.OLS(org_mod_train_y, org_mod_train_x).fit()\n",
    "y_train_pred = olsModel.predict(org_mod_train_x)\n",
    "y_test_pred = olsModel.predict(org_mod_test_x)\n",
    "rm_Score = np.sqrt(mean_squared_error(org_mod_train_y,y_train_pred));\n",
    "print('RMSE Score of OLS', rm_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGDRegressor()\n",
    "#model_fit(sgd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Gradient Descent','sgd.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd = RandomForestRegressor();\n",
    "#model_fit_old(rnd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Random Forest','rnd1.xlsx')\n",
    "#model_fit(rnd,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Random Forest','rnd.xlsx','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaBoost = AdaBoostRegressor()\n",
    "#model_fit(adaBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Ada Boosting','ada.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauBoost = GradientBoostingRegressor()\n",
    "#model_fit_old(gauBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Graudient Boosting','gdb1.xlsx')\n",
    "#model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVR(kernel='linear')\n",
    "#model_fit(svm,org_mod_train_x,org_mod_train_y,org_mod_test_x,'SVM','svm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmLinear = LinearSVR()\n",
    "#model_fit_old(svmLinear,org_mod_train_x,org_mod_train_y,org_mod_test_x,'SVM Linear','svmLinear.xlsx')\n",
    "#model_fit(svmLinear,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'SVM Linear','svmLinear.xlsx','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree \n",
    "If it criterion = 'mse' no need to apply hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeRegressor(criterion='mse')\n",
    "#model_fit_old(decisionTree,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Decision Tree Regression','decision1.xlsx')\n",
    "#model_fit(decisionTree,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Decision Tree Regression','decision1.xlsx','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.1,0.05,0.01,0.001]\n",
    "def check_learn(lRate):\n",
    "    for i in lRate:\n",
    "        print(\"Learning Rate ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',learning_rate=i)\n",
    "        model_fit_old(gauBoost,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Graudient Boosting', 'gdb.xlsx');\n",
    "        #model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_learn(learning_rate)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimate = [15,20,25,30]\n",
    "def check_dept(max_depth_check):\n",
    "    for i in max_depth_check:\n",
    "        print(\"n_estimate ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',learning_rate=0.1,n_estimators=i)\n",
    "        model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_dept(n_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_check = [10,20,30]\n",
    "def check_dept(max_depth_check):\n",
    "    indexi = 0;\n",
    "    for i in max_depth_check:\n",
    "        indexi+= 1;\n",
    "        print(\"Max_ Depth ----------------------- = \",i,indexi)\n",
    "        dt = DecisionTreeRegressor(max_depth=i)\n",
    "        #model_fit_old(rnd,org_mod_train_x,org_mod_train_y,org_mod_test_x,'Random Forest','rnd1.xlsx')\n",
    "        model_fit(dt,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Decision','decisionHyp.xlsx','max_depth_check',max_depth_check, True if(len(max_depth_check) == indexi) else False,False)\n",
    "#check_dept(max_depth_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [0.1, 1.0, 10, 20]\n",
    "def check_split(min_samples_split):\n",
    "    for i in min_samples_split:\n",
    "        print(\"Minimun Sample split ----------------------- = \",i)\n",
    "        dt = GradientBoostingRegressor(criterion='friedman_mse',min_samples_split=i)\n",
    "        model_fit(gauBoost,x_train_split,y_train_split,x_test_split,y_test_split,org_mod_test_x,'Graudient Boosting','gdb.xlsx')\n",
    "#check_split(min_samples_split)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dParams = {\n",
    "    \"criterion\": [\"mse\"],\n",
    "    \"min_samples_split\": [10, 20, 40],\n",
    "    \"max_depth\": [8,10,12,14,18,20],\n",
    "    \"min_samples_leaf\": [20, 40, 100],\n",
    "    \"max_leaf_nodes\": [5, 20, 100]\n",
    "    }\n",
    "lasParams  ={\n",
    "    \"alpha\" : [0.1, 0.5, 1],\n",
    "    \"normalize\" : [True]\n",
    "}\n",
    "dt = DecisionTreeRegressor()\n",
    "gridCV = GridSearchCV(dt,dParams,cv=5)\n",
    "gridCV.fit(x_train_split,y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
